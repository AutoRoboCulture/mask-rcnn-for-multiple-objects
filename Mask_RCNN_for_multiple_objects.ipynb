{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask_RCNN_for_multiple_objects.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AutoRoboCulture/mask-rcnn-for-multiple-objects/blob/master/Mask_RCNN_for_multiple_objects.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQK7KlhRBfnf",
        "colab_type": "text"
      },
      "source": [
        "# Step 1 : Mount Drive + Clone MRCNN Lib + Load Dataset\n",
        "\n",
        "MRCNN Code: [How to Train an Object Detection Model with Keras](https://machinelearningmastery.com/how-to-train-an-object-detection-model-with-keras/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxHv1L-vknYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KffcLJTckbq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvJawUstpQ5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd Mask_RCNN/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI8HpJeupSlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k70vHtWMpX5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip show mask-rcnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDhrXQfrqS8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJz04A9ESvVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Upload your dataset and place it to /content/Mask_RCNN/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V8VEXLE0nSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Making preTrainedWeights directory\n",
        "!mkdir /content/Mask_RCNN/weed_cfg_preTrainedWeights/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb7Y9y5FTDjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Download preTrainedWeights from https://drive.google.com/open?id=1bXEOmOsoBLpXQWVvhhJvhD-RjvCLxOAQ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igyteRViQgcG",
        "colab_type": "text"
      },
      "source": [
        "#**Step 2**: Train Model Here \n",
        "*Change load weight path before run\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J59SHLdMEiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit a mask rcnn on the weed dataset\n",
        "from os import listdir\n",
        "from xml.etree import ElementTree\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "from mrcnn.utils import Dataset\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.model import MaskRCNN\n",
        "import pdb\n",
        "import numpy as np\n",
        "import skimage\n",
        "\n",
        "#pdb.set_trace()\n",
        "\n",
        "# class that defines and loads the weed dataset\n",
        "class WeedDataset(Dataset):\n",
        "\t# load the dataset definitions\n",
        "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
        "\t\t# define two class\n",
        "\t\tself.add_class(\"dataset\", 1, \"crop\")\n",
        "\t\tself.add_class(\"dataset\", 2, \"weed\")\n",
        "\t\t# define data locations\n",
        "\t\timages_dir = dataset_dir + '/images/'\n",
        "\t\tannotations_dir = dataset_dir + '/annots/'\n",
        "\t\t\n",
        "\t\t# find all images\n",
        "\t\tfor filename in listdir(images_dir):\n",
        "\t\t\t# extract image id\n",
        "\t\t\timage_id = filename[:-4]\n",
        "\t\t\t#print('IMAGE ID: ',image_id)\n",
        "\t\t\t# skip bad images\n",
        "\t\t\tif (image_id == '.ipynb_checkpo'):\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t# skip all images after 115 if we are building the train set\n",
        "\t\t\tif is_train and int(image_id) >= 115:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t# skip all images before 115 if we are building the test/val set\n",
        "\t\t\tif not is_train and int(image_id) < 115:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\timg_path = images_dir + filename\n",
        "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
        "\t\t\t# add to dataset\n",
        "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path, class_ids = [0,1,2])\n",
        "\n",
        "\t# extract bounding boxes from an annotation file\n",
        "\tdef extract_boxes(self, filename):\n",
        "\t\t# load and parse the file\n",
        "\t\ttree = ElementTree.parse(filename)\n",
        "\t\t# get the root of the document\n",
        "\t\troot = tree.getroot()\n",
        "\t\t# extract each bounding box\n",
        "\t\tboxes = list()\n",
        "\t\t#for box in root.findall('.//bndbox'):\n",
        "\t\tfor box in root.findall('.//object'):\n",
        "\t\t\tname = box.find('name').text\n",
        "\t\t\txmin = int(box.find('./bndbox/xmin').text)\n",
        "\t\t\tymin = int(box.find('./bndbox/ymin').text)\n",
        "\t\t\txmax = int(box.find('./bndbox/xmax').text)\n",
        "\t\t\tymax = int(box.find('./bndbox/ymax').text)\n",
        "\t\t\t#coors = [xmin, ymin, xmax, ymax, name]\n",
        "\t\t\tcoors = [xmin, ymin, xmax, ymax, name]\n",
        "\t\t\tboxes.append(coors)\n",
        "\t\t# extract image dimensions\n",
        "\t\twidth = int(root.find('.//size/width').text)\n",
        "\t\theight = int(root.find('.//size/height').text)\n",
        "\t\treturn boxes, width, height\n",
        "\n",
        "\t# load the masks for an image\n",
        "\tdef load_mask(self, image_id):\n",
        "\t\t#pdb.set_trace()\n",
        "\t\t# get details of image\n",
        "\t\tinfo = self.image_info[image_id]\n",
        "\t\t# define box file location\n",
        "\t\tpath = info['annotation']\n",
        "\t\t# load XML\n",
        "\t\tboxes, w, h = self.extract_boxes(path)\n",
        "\t\t# create one array for all masks, each on a different channel\n",
        "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
        "\t\t# create masks\n",
        "\t\tclass_ids = list()\n",
        "\t\tfor i in range(len(boxes)):\n",
        "\t\t\tbox = boxes[i]\n",
        "\t\t\trow_s, row_e = box[1], box[3]\n",
        "\t\t\tcol_s, col_e = box[0], box[2]\n",
        "\t\t\tif (box[4] == 'crop'):\n",
        "\t\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 2\n",
        "\t\t\t\tclass_ids.append(self.class_names.index('crop'))\n",
        "\t\t\telse:\n",
        "\t\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
        "\t\t\t\tclass_ids.append(self.class_names.index('weed'))\n",
        "\t\t\t\n",
        "\t\t\t\t\n",
        "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
        "\n",
        "\t# load an image reference\n",
        "\tdef image_reference(self, image_id):\n",
        "\t\tinfo = self.image_info[image_id]\n",
        "\t\treturn info['path']\n",
        "\n",
        "# define a configuration for the model\n",
        "class WeedConfig(Config):\n",
        "\t# define the name of the configuration\n",
        "\tNAME = \"weed_cfg\"\n",
        "\t# number of classes (background + weed + crop)\n",
        "\tNUM_CLASSES = 1 + 2\n",
        "\t# number of training steps per epoch\n",
        "\tSTEPS_PER_EPOCH = 115\n",
        "\n",
        "\n",
        "# prepare train set\n",
        "train_set = WeedDataset()\n",
        "train_set.load_dataset('weed', is_train=True)\n",
        "train_set.prepare()\n",
        "print('Train: %d' % len(train_set.image_ids))\n",
        "# prepare test/val set\n",
        "test_set = WeedDataset()\n",
        "test_set.load_dataset('weed', is_train=False)\n",
        "test_set.prepare()\n",
        "print('Test: %d' % len(test_set.image_ids))\n",
        "# prepare config\n",
        "config = WeedConfig()\n",
        "config.display()\n",
        "# define the model\n",
        "model = MaskRCNN(mode='training', model_dir='./', config=config)\n",
        "# load weights and exclude the output layers\n",
        "model.load_weights('<enter your trained model path>', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "# train weights (output layers or 'heads')\n",
        "model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=60, layers='heads')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f-Pub4gY3gBO",
        "colab": {}
      },
      "source": [
        "#Backup weights to DRIVE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kkqy_D7IWwNo",
        "colab_type": "text"
      },
      "source": [
        "#STEP3: FOR Calculating testMAP\n",
        "**write your preTrained Model path**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB_rOnqETRiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit a mask rcnn on the weed dataset\n",
        "from os import listdir\n",
        "from xml.etree import ElementTree\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "from mrcnn.utils import Dataset\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.model import MaskRCNN\n",
        "import pdb\n",
        "import numpy as np\n",
        "import skimage\n",
        "from numpy import expand_dims\n",
        "from numpy import mean\n",
        "from mrcnn.utils import compute_ap\n",
        "from mrcnn.model import load_image_gt\n",
        "from mrcnn.model import mold_image\n",
        "\n",
        "# class that defines and loads the weed dataset\n",
        "class WeedDataset(Dataset):\n",
        "\t# load the dataset definitions\n",
        "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
        "\t\t# define two class\n",
        "\t\tself.add_class(\"dataset\", 1, \"crop\")\n",
        "\t\tself.add_class(\"dataset\", 2, \"weed\")\n",
        "\t\t# define data locations\n",
        "\t\timages_dir = dataset_dir + '/images/'\n",
        "\t\tannotations_dir = dataset_dir + '/annots/'\n",
        "\t\t\n",
        "\t\t# find all images\n",
        "\t\tfor filename in listdir(images_dir):\n",
        "\t\t\t# extract image id\n",
        "\t\t\timage_id = filename[:-4]\n",
        "\t\t\t#print('IMAGE ID: ',image_id)\n",
        "\t\t\t# skip bad images\n",
        "\t\t\tif (image_id == '.ipynb_checkpo'):\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t# skip all images after 115 if we are building the train set\n",
        "\t\t\tif is_train and int(image_id) >= 115:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t# skip all images before 115 if we are building the test/val set\n",
        "\t\t\tif not is_train and int(image_id) < 115:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\timg_path = images_dir + filename\n",
        "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
        "\t\t\t# add to dataset\n",
        "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path, class_ids = [0,1,2])\n",
        "\n",
        "\t# extract bounding boxes from an annotation file\n",
        "\tdef extract_boxes(self, filename):\n",
        "\t\t# load and parse the file\n",
        "\t\ttree = ElementTree.parse(filename)\n",
        "\t\t# get the root of the document\n",
        "\t\troot = tree.getroot()\n",
        "\t\t# extract each bounding box\n",
        "\t\tboxes = list()\n",
        "\t\t#for box in root.findall('.//bndbox'):\n",
        "\t\tfor box in root.findall('.//object'):\n",
        "\t\t\tname = box.find('name').text\n",
        "\t\t\txmin = int(box.find('./bndbox/xmin').text)\n",
        "\t\t\tymin = int(box.find('./bndbox/ymin').text)\n",
        "\t\t\txmax = int(box.find('./bndbox/xmax').text)\n",
        "\t\t\tymax = int(box.find('./bndbox/ymax').text)\n",
        "\t\t\t#coors = [xmin, ymin, xmax, ymax, name]\n",
        "\t\t\tcoors = [xmin, ymin, xmax, ymax, name]\n",
        "\t\t\tboxes.append(coors)\n",
        "\t\t# extract image dimensions\n",
        "\t\twidth = int(root.find('.//size/width').text)\n",
        "\t\theight = int(root.find('.//size/height').text)\n",
        "\t\treturn boxes, width, height\n",
        "\n",
        "\t# load the masks for an image\n",
        "\tdef load_mask(self, image_id):\n",
        "\t\t#pdb.set_trace()\n",
        "\t\t# get details of image\n",
        "\t\tinfo = self.image_info[image_id]\n",
        "\t\t# define box file location\n",
        "\t\tpath = info['annotation']\n",
        "\t\t# load XML\n",
        "\t\tboxes, w, h = self.extract_boxes(path)\n",
        "\t\t# create one array for all masks, each on a different channel\n",
        "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
        "\t\t# create masks\n",
        "\t\tclass_ids = list()\n",
        "\t\tfor i in range(len(boxes)):\n",
        "\t\t\tbox = boxes[i]\n",
        "\t\t\trow_s, row_e = box[1], box[3]\n",
        "\t\t\tcol_s, col_e = box[0], box[2]\n",
        "\t\t\tif (box[4] == 'crop'):\n",
        "\t\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 2\n",
        "\t\t\t\tclass_ids.append(self.class_names.index('crop'))\n",
        "\t\t\telse:\n",
        "\t\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
        "\t\t\t\tclass_ids.append(self.class_names.index('weed'))\n",
        "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
        "\t\n",
        "\t\t# calculate the mAP for a model on a given dataset\n",
        "\t\tdef evaluate_model(dataset, model, cfg):\n",
        "\t\tAPs = list()\n",
        "\t\tfor image_id in dataset.image_ids:\n",
        "\t\t\t# load image, bounding boxes and masks for the image id\n",
        "\t\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
        "\t\t\t# convert pixel values (e.g. center)\n",
        "\t\t\tscaled_image = mold_image(image, cfg)\n",
        "\t\t\t# convert image into one sample\n",
        "\t\t\tsample = expand_dims(scaled_image, 0)\n",
        "\t\t\t# make prediction\n",
        "\t\t\tyhat = model.detect(sample, verbose=0)\n",
        "\t\t\t# extract results for first sample\n",
        "\t\t\tr = yhat[0]\n",
        "\t\t\t# calculate statistics, including AP\n",
        "\t\t\tAP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "\t\t\t# store\n",
        "\t\t\tAPs.append(AP)\n",
        "\t\t# calculate the mean AP across all images\n",
        "\t\tmAP = mean(APs)\n",
        "\t\treturn mAP\n",
        "\n",
        "\t# load an image reference\n",
        "\tdef image_reference(self, image_id):\n",
        "\t\tinfo = self.image_info[image_id]\n",
        "\t\treturn info['path']\n",
        "\n",
        "# define a configuration for the model\n",
        "class WeedConfig(Config):\n",
        "\t# define the name of the configuration\n",
        "\tNAME = \"weed_cfg\"\n",
        "\t# number of classes (background + weed + crop)\n",
        "\tNUM_CLASSES = 1 + 2\n",
        "\t# number of training steps per epoch\n",
        "\tSTEPS_PER_EPOCH = 115\n",
        "\n",
        "\n",
        "# prepare train set\n",
        "train_set = WeedDataset()\n",
        "train_set.load_dataset('weed', is_train=True)\n",
        "train_set.prepare()\n",
        "print('Train: %d' % len(train_set.image_ids))\n",
        "# prepare test/val set\n",
        "test_set = WeedDataset()\n",
        "test_set.load_dataset('weed', is_train=False)\n",
        "test_set.prepare()\n",
        "print('Test: %d' % len(test_set.image_ids))\n",
        "# prepare config\n",
        "config = WeedConfig()\n",
        "config.display()\n",
        "# define the model\n",
        "model = MaskRCNN(mode='training', model_dir='./', config=config)\n",
        "# load weights and exclude the output layers\n",
        "model.load_weights('<enter your trained model path>', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "# evaluate model on training dataset\n",
        "train_mAP = evaluate_model(train_set, model, cfg)\n",
        "print(\"Train mAP: %.3f\" % train_mAP)\n",
        "# evaluate model on test dataset\n",
        "test_mAP = evaluate_model(test_set, model, cfg)\n",
        "print(\"Test mAP: %.3f\" % test_mAP)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJn-VmBtXE82",
        "colab_type": "text"
      },
      "source": [
        "# Step 4: For predict Image using PreTrained Weights (.h5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW-p7r5tEtlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate the mask rcnn model on the kangaroo dataset\n",
        "import time\n",
        "start1 = time.time()\n",
        "from os import listdir\n",
        "from xml.etree import ElementTree\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "from numpy import expand_dims\n",
        "from numpy import mean\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.model import MaskRCNN\n",
        "from mrcnn.utils import Dataset\n",
        "from mrcnn.utils import compute_ap\n",
        "from mrcnn.model import load_image_gt\n",
        "from mrcnn.model import mold_image\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        "import skimage\n",
        "import numpy as np\n",
        "import pdb\n",
        "import cv2\n",
        "\n",
        "import glob\n",
        "import pdb\n",
        "import os\n",
        "import re\n",
        "\n",
        "# class that defines and loads the weed dataset\n",
        "class WeedDataset(Dataset):\n",
        "\t# load the dataset definitions\n",
        "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
        "\t\t# define classes\n",
        "\t\tself.add_class(\"dataset\", 1, \"crop\")\n",
        "\t\tself.add_class(\"dataset\", 2, \"weed\")\n",
        "\t\t# define data locations\n",
        "\t\timages_dir = dataset_dir + '/images/'\n",
        "\t\tannotations_dir = dataset_dir + '/annots/'\n",
        "\t\t# find all images\n",
        "\t\tfor filename in listdir(images_dir):\n",
        "\t\t\t# extract image id\n",
        "\t\t\timage_id = filename[:-4]\n",
        "\t\t\t# skip bad images\n",
        "\t\t\tif (image_id == '.ipynb_checkpo'):\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t# skip all images after 115 if we are building the train set\n",
        "\t\t\tif is_train and int(image_id) >= 115:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t# skip all images before 115 if we are building the test/val set\n",
        "\t\t\tif not is_train and int(image_id) < 115:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\timg_path = images_dir + filename\n",
        "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
        "\t\t\t# add to dataset\n",
        "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
        "\n",
        "\t# extract bounding boxes from an annotation file\n",
        "\tdef extract_boxes(self, filename):\n",
        "\t\t# load and parse the file\n",
        "\t\ttree = ElementTree.parse(filename)\n",
        "\t\t# get the root of the document\n",
        "\t\troot = tree.getroot()\n",
        "\t\t# extract each bounding box\n",
        "\t\tboxes = list()\n",
        "\t\t#for box in root.findall('.//bndbox'):\n",
        "\t\tfor box in root.findall('.//object'):\n",
        "\t\t\tname = box.find('name').text\n",
        "\t\t\txmin = int(box.find('./bndbox/xmin').text)\n",
        "\t\t\tymin = int(box.find('./bndbox/ymin').text)\n",
        "\t\t\txmax = int(box.find('./bndbox/xmax').text)\n",
        "\t\t\tymax = int(box.find('./bndbox/ymax').text)\n",
        "\t\t\t#coors = [xmin, ymin, xmax, ymax, name]\n",
        "\t\t\tcoors = [xmin, ymin, xmax, ymax, name]\n",
        "\t\t\tboxes.append(coors)\n",
        "\t\t# extract image dimensions\n",
        "\t\twidth = int(root.find('.//size/width').text)\n",
        "\t\theight = int(root.find('.//size/height').text)\n",
        "\t\treturn boxes, width, height\n",
        "\n",
        "\t# load the masks for an image\n",
        "\tdef load_mask(self, image_id):\n",
        "\t\t#pdb.set_trace()\n",
        "\t\t# get details of image\n",
        "\t\tinfo = self.image_info[image_id]\n",
        "\t\t# define box file location\n",
        "\t\tpath = info['annotation']\n",
        "\t\t# load XML\n",
        "\t\tboxes, w, h = self.extract_boxes(path)\n",
        "\t\t# create one array for all masks, each on a different channel\n",
        "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
        "\t\t# create masks\n",
        "\t\tclass_ids = list()\n",
        "\t\tfor i in range(len(boxes)):\n",
        "\t\t\tbox = boxes[i]\n",
        "\t\t\trow_s, row_e = box[1], box[3]\n",
        "\t\t\tcol_s, col_e = box[0], box[2]\n",
        "\t\t\tif (box[4] == 'crop'):\n",
        "\t\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 2\n",
        "\t\t\t\tclass_ids.append(self.class_names.index('crop'))\n",
        "\t\t\telse:\n",
        "\t\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
        "\t\t\t\tclass_ids.append(self.class_names.index('weed'))\n",
        "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
        "\n",
        "\t# load an image reference\n",
        "\tdef image_reference(self, image_id):\n",
        "\t\tinfo = self.image_info[image_id]\n",
        "\t\treturn info['path']\n",
        "\n",
        "# define the prediction configuration\n",
        "class PredictionConfig(Config):\n",
        "\t# define the name of the configuration\n",
        "\tNAME = \"weed_cfg\"\n",
        "\t# number of classes (background + weed + crop)\n",
        "\tNUM_CLASSES = 1 + 2\n",
        "\t# simplify GPU config\n",
        "\tGPU_COUNT = 1\n",
        "\tIMAGES_PER_GPU = 1\n",
        "\n",
        "# calculate the mAP for a model on a given dataset\n",
        "def evaluate_model(dataset, model, cfg):\n",
        "\tAPs = list()\n",
        "\tfor image_id in dataset.image_ids:\n",
        "\t\t# load image, bounding boxes and masks for the image id\n",
        "\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
        "\t\t# convert pixel values (e.g. center)\n",
        "\t\tscaled_image = mold_image(image, cfg)\n",
        "\t\t# convert image into one sample\n",
        "\t\tsample = expand_dims(scaled_image, 0)\n",
        "\t\t# make prediction\n",
        "\t\tyhat = model.detect(sample, verbose=0)\n",
        "\t\t# extract results for first sample\n",
        "\t\tr = yhat[0]\n",
        "\t\t# calculate statistics, including AP\n",
        "\t\tAP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "\t\t# store\n",
        "\t\tAPs.append(AP)\n",
        "\t# calculate the mean AP across all images\n",
        "\tmAP = mean(APs)\n",
        "\treturn mAP\n",
        "\n",
        "# plot a number of photos with ground truth and predictions\n",
        "def plot_actual_vs_predicted(dataset, model, cfg, n_images=1):\n",
        "\ttimes = []\n",
        "\timgExt = 'png'\n",
        "\tinput_path = '<enter input image folder path/*.>' + imgExt\n",
        "\toutput_path = '<enter output image save folder path/'\n",
        "\tnameR = input_path.replace('*.'+imgExt,'')\n",
        "\tpathR, dirsR, filesR = next(os.walk(nameR))\n",
        "\tfile_count = len(filesR)\n",
        "\t#pdb.set_trace()\n",
        "\n",
        "\timg_num = 0     #file number initial\n",
        "\t\n",
        "\tcnt = 0\n",
        "\tdel_img = []\n",
        "\tfile_name = '%05d.'+imgExt\n",
        "\toutput_path = output_path+file_name     #Output Image Filename\n",
        "\t#pdb.set_trace()\n",
        "\tsort_temp = []\n",
        "\tdef natural_sort(l): \n",
        "\t\tconvert = lambda text: int(text) if text.isdigit() else text.lower() \n",
        "\t\talphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
        "\t\treturn sorted(l, key = alphanum_key)\n",
        "\n",
        "\tfor img_jpg1 in glob.glob(input_path):\n",
        "\t\t\tsort_temp.append(img_jpg1)\n",
        "\tsort = natural_sort(sort_temp)\n",
        "\n",
        "\tfor img_jpg in sort:\n",
        "\n",
        "\t\t\tfilename = output_path%int(img_num)        #Output Image filename\n",
        "\t\t\tcnt+=1\n",
        "\t\t\timg_num+=1\n",
        "\t\t\tprint ('Renamed: ',cnt,'Out of: ',file_count)\n",
        "\n",
        "\t\t\timage = skimage.io.imread(img_jpg) #dataset.load_image(i+15)\n",
        "\t\t\toverlay = image.copy()\n",
        "\t\t\tsample = expand_dims(image, 0)\n",
        "\t\t\tstart3 = time.time()\n",
        "\t\t\tyhat = model.detect(sample, verbose=0)[0]\n",
        "\t\t\tdelta = (time.time() - start3)\n",
        "\t\t\ttimes.append(delta)\n",
        "\t\t\tboxCount = 0\n",
        "\t\t\talpha = 0.4\n",
        "\t\t\tfor classId in yhat['class_ids']:\n",
        "\t\t\t\tif (classId == 2):\n",
        "\t\t\t\t\tbox = yhat['rois'][boxCount]\n",
        "\t\t\t\t\t# get coordinates\n",
        "\t\t\t\t\ty1, x1, y2, x2 = box\n",
        "\t\t\t\t\tcv2.rectangle(overlay, (x1,y1), (x2,y2), (150,0,0) , -1)\n",
        "\t\t\t\t\tpredictedImage = cv2.addWeighted(overlay, alpha, image, 1-alpha, 0)\n",
        "\t\t\t\t\tpredictedImage = cv2.cvtColor(predictedImage,cv2.COLOR_BGR2RGB)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tbox = yhat['rois'][boxCount]\n",
        "\t\t\t\t\t# get coordinates\n",
        "\t\t\t\t\ty1, x1, y2, x2 = box\n",
        "\t\t\t\t\tcv2.rectangle(overlay, (x1,y1), (x2,y2), (0,0,150) , -1)\n",
        "\t\t\t\t\tpredictedImage = cv2.addWeighted(overlay, alpha, image, 1-alpha, 0)\n",
        "\t\t\t\t\tpredictedImage = cv2.cvtColor(predictedImage,cv2.COLOR_BGR2RGB)\n",
        "\t\t\t\tcv2.imwrite(filename,predictedImage)\n",
        "\t\t\t\tboxCount+=1\n",
        "\n",
        "# load the train dataset\n",
        "train_set = WeedDataset()\n",
        "train_set.load_dataset('weed', is_train=True)\n",
        "train_set.prepare()\n",
        "print('Train: %d' % len(train_set.image_ids))\n",
        "# load the test dataset\n",
        "test_set = WeedDataset()\n",
        "test_set.load_dataset('weed', is_train=False)\n",
        "test_set.prepare()\n",
        "print('Test: %d' % len(test_set.image_ids))\n",
        "# create config\n",
        "cfg = PredictionConfig()\n",
        "# define the model\n",
        "model = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n",
        "# load model weights\n",
        "model_path = '<enter your model pretrained weights path>'\n",
        "model.load_weights(model_path, by_name=True)\n",
        "# plot predictions for train dataset\n",
        "plot_actual_vs_predicted(train_set, model, cfg)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Yp-RDnCzodb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Backup weights to DRIVE"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
